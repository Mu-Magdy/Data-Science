{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af533168",
   "metadata": {},
   "source": [
    "# 1. Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8f1d7f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.5.0)\n",
      "Collecting tensorflow-gpu==2.5\n",
      "  Downloading tensorflow_gpu-2.5.0-cp39-cp39-win_amd64.whl (422.6 MB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.5.4.58)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (0.8.8.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (0.12.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.1.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (3.17.3)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow==2.5) (1.34.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.5.4.58)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (56.0.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (0.4.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (1.32.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow==2.5) (0.6.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (1.3.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2.10)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (3.1.1)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.5 tensorflow-gpu==2.5 opencv-python mediapipe sklearn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a10d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "from matplotlib import pyplot as plt\n",
    "import time \n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec8b98",
   "metadata": {},
   "source": [
    "# 2. Keypoints using MP Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026ef3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic=mp.solutions.holistic\n",
    "mp_drawing=mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0950f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image =cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable=False\n",
    "    results=model.process(image)\n",
    "    image.flags.writeable=True\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "    return image,results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c4c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION)\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)    \n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)    \n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9c2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121),thickness=1,circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,70,10),thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121),thickness=2,circle_radius=2)\n",
    "                             )    \n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76),thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250),thickness=2,circle_radius=2)\n",
    "                             )    \n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66),thickness=2,circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230),thickness=2,circle_radius=2)\n",
    "                             )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a97f05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    " \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        image,results=mediapipe_detection(frame,holistic)\n",
    "        #print(results)\n",
    "        draw_styled_landmarks(image,results)\n",
    "        cv2.imshow('OpenCV Feed',image)\n",
    "        if cv2.waitKey(10) & 0xff==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3f79ef",
   "metadata": {},
   "source": [
    "# 3.Extract keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3de6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "rh=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "lh=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "face=np.array([[res.x,res.y,res.z] fddor res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "488cfe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "    rh=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    lh=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "    return np.concatenate([pose,face,lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8f2cc",
   "metadata": {},
   "source": [
    "# 4. Setup folders for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d92968",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=os.path.join('MP_Data')\n",
    "actions=np.array(['hello','thanks','iloveyou'])\n",
    "no_sequences=30\n",
    "sequence_length=30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af54b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions :\n",
    "    for sequence in range(no_sequences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH,action,str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f7d58",
   "metadata": {},
   "source": [
    "# 5. Collect keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9799e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    " \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    for action in actions:\n",
    "        for sequence in range(no_sequences):\n",
    "            for frame_num in range(sequence_length):\n",
    "                ret,frame=cap.read()\n",
    "                image,results=mediapipe_detection(frame,holistic)\n",
    "                #print(results)\n",
    "                draw_styled_landmarks(image,results)\n",
    "                \n",
    "                if frame_num ==0:\n",
    "                    cv2.putText(image,\"Starting Collection \",(120,200),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),4,cv2.LINE_AA)\n",
    "                    cv2.putText(image,f\"Collecting frames for {action} video number {sequence} \",(15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(500)\n",
    "                else:\n",
    "                    cv2.putText(image,f\"Collecting frames for {action} video number {sequence} \",(15,12),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    \n",
    "                keypoints=extract_keypoints(results)\n",
    "                npy_path=os.path.join(DATA_PATH,action,str(sequence),str(frame_num))\n",
    "                np.save(npy_path,keypoints)\n",
    "                #cv2.imshow('OpenCV Feed',image)\n",
    "\n",
    "                if cv2.waitKey(10) & 0xff==ord('q'):\n",
    "                    break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c5c0d",
   "metadata": {},
   "source": [
    "# 6. Preprocess Data and Create labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45c39180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06d18ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map={label:num for num,label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02cbb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences ,labels =[],[]\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window=[]\n",
    "        for frame_num in range(sequence_length):\n",
    "            res=np.load(os.path.join(DATA_PATH,action,str(sequence),f'{frame_num}.npy'))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9e3a1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eecbdee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77b9e126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "807286b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd7e15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "176dc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f756df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115bcb98",
   "metadata": {},
   "source": [
    "# 7. Build and train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b840010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense \n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3118120",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir=os.path.join(\"Logs\")\n",
    "tb_callback=TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "789a0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2da40c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a2740feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 9s 1s/step - loss: 1.4494 - categorical_accuracy: 0.3176\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 308ms/step - loss: 1.5017 - categorical_accuracy: 0.2588\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 1.8391 - categorical_accuracy: 0.2588\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 1s 349ms/step - loss: 3.0849 - categorical_accuracy: 0.2824\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 10.7424 - categorical_accuracy: 0.3294\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 11.5532 - categorical_accuracy: 0.3529\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 1s 135ms/step - loss: 12.9625 - categorical_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 18.3348 - categorical_accuracy: 0.4235\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 96.3912 - categorical_accuracy: 0.2471\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 183.3387 - categorical_accuracy: 0.2706\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 151.4896 - categorical_accuracy: 0.3059\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 100.2592 - categorical_accuracy: 0.5647\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 320.6012 - categorical_accuracy: 0.3059\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 155.1231 - categorical_accuracy: 0.3529\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 240.5832 - categorical_accuracy: 0.3529\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 138.7952 - categorical_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 106.0692 - categorical_accuracy: 0.3059\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 139.6618 - categorical_accuracy: 0.3765\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 274.5179 - categorical_accuracy: 0.3059\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 155.4144 - categorical_accuracy: 0.2000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 119.2962 - categorical_accuracy: 0.3765\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 97.0681 - categorical_accuracy: 0.2824\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 68.8408 - categorical_accuracy: 0.2353\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 182.0282 - categorical_accuracy: 0.4118\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 120.8642 - categorical_accuracy: 0.3647\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 91.8005 - categorical_accuracy: 0.3176\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 114.3149 - categorical_accuracy: 0.3529\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 88.0452 - categorical_accuracy: 0.4118\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 116.1765 - categorical_accuracy: 0.3059\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 56.5133 - categorical_accuracy: 0.3412\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 33.4027 - categorical_accuracy: 0.3412\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 9.0616 - categorical_accuracy: 0.4471\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 12.2916 - categorical_accuracy: 0.3059\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 67.4796 - categorical_accuracy: 0.3176\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 76.6567 - categorical_accuracy: 0.3176\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 51.4844 - categorical_accuracy: 0.3176\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 56.8841 - categorical_accuracy: 0.3529\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 54.1610 - categorical_accuracy: 0.4118\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 52.8563 - categorical_accuracy: 0.3176\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 37.7707 - categorical_accuracy: 0.3647\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 34.1731 - categorical_accuracy: 0.3176\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 24.9791 - categorical_accuracy: 0.3294\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 25.9545 - categorical_accuracy: 0.2941\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 19.0841 - categorical_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 31.4237 - categorical_accuracy: 0.4118\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 158.0641 - categorical_accuracy: 0.2941\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 96.8537 - categorical_accuracy: 0.3529\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 74.4444 - categorical_accuracy: 0.3176\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 58.0328 - categorical_accuracy: 0.3176\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 131.2300 - categorical_accuracy: 0.3647\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 190.6241 - categorical_accuracy: 0.3294\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 60.0363 - categorical_accuracy: 0.3765\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 27.4672 - categorical_accuracy: 0.4118\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 32.7499 - categorical_accuracy: 0.3294\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 18.4452 - categorical_accuracy: 0.3529\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 49.1639 - categorical_accuracy: 0.3529\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 180ms/step - loss: 42.8815 - categorical_accuracy: 0.3059\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 57.3580 - categorical_accuracy: 0.3294\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 20.0244 - categorical_accuracy: 0.3294\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 21.5691 - categorical_accuracy: 0.3647\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 25.3639 - categorical_accuracy: 0.3529\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 18.6507 - categorical_accuracy: 0.3294\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 32.2114 - categorical_accuracy: 0.3176\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 18.9303 - categorical_accuracy: 0.3294\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 31.8439 - categorical_accuracy: 0.3059\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 28.6544 - categorical_accuracy: 0.2824\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 18.9021 - categorical_accuracy: 0.2706\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 7.6305 - categorical_accuracy: 0.3529\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 11.6278 - categorical_accuracy: 0.3765\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 27.8452 - categorical_accuracy: 0.3059\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 21.3839 - categorical_accuracy: 0.3647\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 34.2889 - categorical_accuracy: 0.3059\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 130ms/step - loss: 21.0993 - categorical_accuracy: 0.4000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 13.6071 - categorical_accuracy: 0.3529\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 27.8411 - categorical_accuracy: 0.3882\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 33.4303 - categorical_accuracy: 0.3294\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 18.3211 - categorical_accuracy: 0.3529\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 23.2389 - categorical_accuracy: 0.3176\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 26.6675 - categorical_accuracy: 0.3765\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 40.2419 - categorical_accuracy: 0.2941\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 30.0521 - categorical_accuracy: 0.2941\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 14.5023 - categorical_accuracy: 0.3294\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 24.6357 - categorical_accuracy: 0.3647\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 18.4068 - categorical_accuracy: 0.3412\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 17.0815 - categorical_accuracy: 0.3294\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 11.3143 - categorical_accuracy: 0.2353\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 18.3189 - categorical_accuracy: 0.3765\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 22.5051 - categorical_accuracy: 0.2235\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 24.8757 - categorical_accuracy: 0.3294\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 18.1118 - categorical_accuracy: 0.3059\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 20.9517 - categorical_accuracy: 0.3059\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 7.6088 - categorical_accuracy: 0.3294\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 6.0518 - categorical_accuracy: 0.3882\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 9.0354 - categorical_accuracy: 0.3647\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 18.1046 - categorical_accuracy: 0.3294\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 9.7198 - categorical_accuracy: 0.3294\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 23.4736 - categorical_accuracy: 0.3529\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 12.2158 - categorical_accuracy: 0.3882\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 17.6131 - categorical_accuracy: 0.3059\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 7.7035 - categorical_accuracy: 0.3294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28077db9040>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ed814a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 30, 64)            442112    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 30, 128)           98816     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6251864",
   "metadata": {},
   "source": [
    "# 8. model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a921dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91f20456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iloveyou'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c9f460d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77814f83",
   "metadata": {},
   "source": [
    "# 9. Save Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9bb2ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd5617",
   "metadata": {},
   "source": [
    "# 10.Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "223c17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e99513b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b7f7912",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue=np.argmax(y_test,axis=1).tolist()\n",
    "yhat=np.argmax(yhat,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eab62845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a83171f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3., 0.],\n",
       "        [2., 0.]],\n",
       "\n",
       "       [[2., 0.],\n",
       "        [3., 0.]],\n",
       "\n",
       "       [[0., 5.],\n",
       "        [0., 0.]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d3e27bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306f8ba",
   "metadata": {},
   "source": [
    "# 11. Test in Real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "19a2a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=[(245,117,16),(117,245,16),(16,117,245)]\n",
    "def prob_viz(res,actions,input_frame,colors):\n",
    "    output_frame=input_frame.copy()\n",
    "    for num,prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame,(0,60+num*40),(int(prob*100),90+num*40),colors[num],-1)\n",
    "        cv2.putText(output_frame,actions[num],(0,85+num*40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b7643361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n",
      "thanks\n",
      "iloveyou\n"
     ]
    }
   ],
   "source": [
    "sequence=[]\n",
    "sentence=[]\n",
    "predictions=[]\n",
    "threshold=0.5\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    " \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        image,results=mediapipe_detection(frame,holistic)\n",
    "        #print(results)\n",
    "        draw_styled_landmarks(image,results)\n",
    "        \n",
    "        keypoints=extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence=sequence[-30:]\n",
    "        \n",
    "        if len(sequence)==30:\n",
    "            res=model.predict(np.expand_dims(sequence,axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res):\n",
    "                if res[np.argmax(res)]>threshold:\n",
    "                    if len(sentence)>0:\n",
    "                        if actions[np.argmax(res)]!=sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else: \n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence)>5:\n",
    "                sentence=sentence[-5:]\n",
    "            image= prob_viz(res,actions,image,colors)\n",
    "        \n",
    "        cv2.rectangle(image,(0,0),(640,40),(245,117,16),-1)\n",
    "        cv2.putText(image,' '.join(sentence),(3,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        cv2.imshow('OpenCV Feed',image)\n",
    "        if cv2.waitKey(10) & 0xff==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "992006af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc9402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332f02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c8e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
